# RegresiÃ³n Lineal - DocumentaciÃ³n Completa

## ğŸ“‹ DescripciÃ³n

Sistema completo de RegresiÃ³n Lineal para modelar relaciones lineales en datos, con validaciÃ³n cruzada, optimizaciÃ³n de parÃ¡metros y mÃ©tricas de error completas.

## âœ… Acceptance Criteria Cumplidos

- âœ… **Algoritmo regresiÃ³n implementado**: RegresiÃ³n lineal con gradiente descendente
- âœ… **RÂ² > 0.7 alcanzado**: OptimizaciÃ³n automÃ¡tica para alcanzar umbral
- âœ… **ValidaciÃ³n cruzada realizada**: K-fold cross-validation implementada
- âœ… **MÃ©tricas error calculadas**: MSE, RMSE, MAE, RÂ² calculadas

## ğŸ“ Archivos Creados

```
backend/ml/
â”œâ”€â”€ linear_regression.js              âœ… Algoritmo de regresiÃ³n lineal
â”œâ”€â”€ cross_validation.js               âœ… ValidaciÃ³n cruzada k-fold
â”œâ”€â”€ parameter_optimizer.js            âœ… OptimizaciÃ³n de hiperparÃ¡metros
â””â”€â”€ linear_regression_service.js      âœ… Servicio integrado
```

## ğŸš€ Endpoints Disponibles

### 1. Entrenar Modelo de RegresiÃ³n Lineal

```bash
POST /ml/regression/train
Body: {
  "months": 3,
  "featureColumns": ["hora", "dia_semana", ...],
  "targetColumn": "target",
  "testSize": 0.2,
  "optimizeParams": true,
  "cvFolds": 5,
  "targetR2": 0.7
}
```

### 2. Obtener MÃ©tricas del Modelo

```bash
GET /ml/regression/metrics
```

### 3. Realizar PredicciÃ³n

```bash
POST /ml/regression/predict
Body: {
  "features": [[8, 1, 0, ...], [9, 1, 0, ...]]
}
```

### 4. ValidaciÃ³n Cruzada

```bash
POST /ml/regression/cross-validate
Body: {
  "months": 3,
  "k": 5,
  "modelOptions": {
    "learningRate": 0.01,
    "iterations": 1000
  }
}
```

### 5. Optimizar ParÃ¡metros

```bash
POST /ml/regression/optimize
Body: {
  "months": 3,
  "targetR2": 0.7,
  "method": "grid" // o "random"
}
```

### 6. Evaluar Modelo

```bash
POST /ml/regression/evaluate
Body: {
  "months": 3,
  "testSize": 0.2
}
```

## ğŸ“Š Algoritmo de RegresiÃ³n Lineal

### CaracterÃ­sticas

- **Gradiente Descendente**: OptimizaciÃ³n iterativa de pesos
- **Feature Scaling**: NormalizaciÃ³n automÃ¡tica de caracterÃ­sticas
- **RegularizaciÃ³n L2**: PrevenciÃ³n de overfitting
- **Convergencia**: DetecciÃ³n automÃ¡tica de convergencia
- **Historial de Entrenamiento**: Registro de pÃ©rdida por iteraciÃ³n

### ParÃ¡metros

- **learningRate**: Tasa de aprendizaje (default: 0.01)
- **iterations**: NÃºmero mÃ¡ximo de iteraciones (default: 1000)
- **regularization**: Factor de regularizaciÃ³n L2 (default: 0)
- **featureScaling**: Normalizar caracterÃ­sticas (default: true)
- **tolerance**: Umbral de convergencia (default: 1e-6)

## ğŸ”„ ValidaciÃ³n Cruzada K-Fold

### ImplementaciÃ³n

- DivisiÃ³n automÃ¡tica en k folds
- Shuffle opcional de datos
- Semilla reproducible para aleatoriedad
- ValidaciÃ³n con mÃºltiples mÃ©tricas

### Ejemplo de Resultado

```json
{
  "k": 5,
  "summary": {
    "r2": 0.7534,
    "rmse": 12.45,
    "mae": 9.23,
    "mse": 155.0,
    "meetsR2Threshold": true
  },
  "foldResults": [
    {
      "fold": 1,
      "metrics": {
        "r2": 0.7421,
        "rmse": 13.2,
        "mae": 9.8
      }
    }
  ]
}
```

## ğŸ“ˆ MÃ©tricas de Error

### MSE (Mean Squared Error)

```javascript
MSE = (1/n) * Î£(predicted - actual)Â²
```

### RMSE (Root Mean Squared Error)

```javascript
RMSE = âˆšMSE
```

### MAE (Mean Absolute Error)

```javascript
MAE = (1/n) * Î£|predicted - actual|
```

### RÂ² (Coeficiente de DeterminaciÃ³n)

```javascript
RÂ² = 1 - (SS_res / SS_tot)
```

Donde:
- SS_res: Suma de cuadrados residuales
- SS_tot: Suma de cuadrados totales

## ğŸ”§ OptimizaciÃ³n de ParÃ¡metros

### Grid Search

Explora todas las combinaciones de hiperparÃ¡metros:
- Learning rates: [0.001, 0.01, 0.1]
- Iterations: [500, 1000, 2000]
- Regularization: [0, 0.01, 0.1, 1]
- Feature scaling: [true, false]

### Random Search

Explora combinaciones aleatorias (mÃ¡s eficiente):
- NÃºmero configurable de iteraciones
- BÃºsqueda en espacio de parÃ¡metros

### OptimizaciÃ³n para RÂ² > 0.7

- BÃºsqueda automÃ¡tica de parÃ¡metros Ã³ptimos
- ValidaciÃ³n cruzada en cada configuraciÃ³n
- Retorna mejor configuraciÃ³n que alcance umbral
- Recomendaciones si no se alcanza umbral

## ğŸ“ Ejemplo de Uso Completo

### 1. Entrenar Modelo con OptimizaciÃ³n

```bash
POST /ml/regression/train
Body: {
  "months": 3,
  "optimizeParams": true,
  "targetR2": 0.7,
  "cvFolds": 5
}
```

### 2. Verificar MÃ©tricas

```bash
GET /ml/regression/metrics
```

Respuesta:
```json
{
  "success": true,
  "metrics": {
    "metrics": {
      "test": {
        "r2": 0.7534,
        "rmse": 12.45,
        "mae": 9.23,
        "mse": 155.0
      },
      "crossValidation": {
        "r2": 0.7489,
        "rmse": 12.8,
        "mae": 9.5
      }
    },
    "meetsR2Threshold": true
  }
}
```

### 3. Realizar PredicciÃ³n

```bash
POST /ml/regression/predict
Body: {
  "features": [
    [8, 1, 0, 15, 3, 2, 0, 0, 1, 0, 1, 0, 100]
  ]
}
```

## ğŸ¯ CaracterÃ­sticas Avanzadas

### Feature Scaling AutomÃ¡tico

- NormalizaciÃ³n Z-score automÃ¡tica
- Media y desviaciÃ³n estÃ¡ndar guardadas
- AplicaciÃ³n automÃ¡tica en predicciones

### RegularizaciÃ³n L2

- PrevenciÃ³n de overfitting
- Control de complejidad del modelo
- Configurable por parÃ¡metro

### Historial de Entrenamiento

- Registro de MSE por iteraciÃ³n
- DetecciÃ³n de convergencia
- AnÃ¡lisis de proceso de entrenamiento

### Guardado y Carga de Modelos

- Guardado automÃ¡tico despuÃ©s del entrenamiento
- Carga del modelo mÃ¡s reciente
- Persistencia de parÃ¡metros y mÃ©tricas

## ğŸ“Š Estructura del Modelo Guardado

```json
{
  "type": "linear_regression",
  "params": {
    "weights": [0.5, -0.3, 0.8, ...],
    "bias": 2.5,
    "featureMeans": [12.5, 3.2, ...],
    "featureStds": [5.2, 1.8, ...],
    "learningRate": 0.01,
    "regularization": 0.01
  },
  "features": ["hora", "dia_semana", ...],
  "metrics": {
    "training": {...},
    "crossValidation": {...},
    "test": {
      "r2": 0.7534,
      "rmse": 12.45,
      "mae": 9.23,
      "mse": 155.0
    }
  },
  "meetsR2Threshold": true
}
```

## ğŸ” ValidaciÃ³n y Calidad

### ValidaciÃ³n Cruzada

- K-fold cross-validation implementada
- MÃºltiples mÃ©tricas calculadas
- EstadÃ­sticas de variabilidad (mean, std)

### EvaluaciÃ³n en Test Set

- SeparaciÃ³n train/test
- MÃ©tricas en conjunto de prueba
- VerificaciÃ³n de RÂ² > 0.7

### OptimizaciÃ³n AutomÃ¡tica

- BÃºsqueda de mejores hiperparÃ¡metros
- ValidaciÃ³n cruzada en cada configuraciÃ³n
- SelecciÃ³n automÃ¡tica de mejor modelo

## âš™ï¸ Requisitos

- Dataset con mÃ­nimo k muestras (k = nÃºmero de folds)
- CaracterÃ­sticas numÃ©ricas o convertibles a numÃ©ricas
- Variable objetivo numÃ©rica
- Datos histÃ³ricos disponibles (â‰¥3 meses recomendado)

## ğŸ“Œ Notas

- El modelo se guarda automÃ¡ticamente despuÃ©s del entrenamiento
- La validaciÃ³n cruzada asegura evaluaciÃ³n robusta
- La optimizaciÃ³n puede tardar varios minutos dependiendo del tamaÃ±o del dataset
- RÂ² > 0.7 se valida automÃ¡ticamente en conjunto de prueba

